{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByzJAb-3v5jA"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "API_KEY = userdata.get('GoogleAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "Di3LuXAeIKet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=API_KEY)\n",
        "gemini = genai.GenerativeModel(model_name=\"models/gemini-2.0-flash-exp\")"
      ],
      "metadata": {
        "id": "Q4LNHyGeyhFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", google_api_key=API_KEY)\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "OAy4SqMlI1Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = gemini.generate_content('who are you?')"
      ],
      "metadata": {
        "id": "98Iw3J6ZKE_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res)"
      ],
      "metadata": {
        "id": "HOkzHLQiKlL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "loader = CSVLoader(\"dataset.csv\")\n",
        "\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "l1jXIuMQ8FxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:5]"
      ],
      "metadata": {
        "id": "m2sGiYfdTkz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in data[:5]:  # Check the first 5 entries\n",
        "    print(doc.page_content)"
      ],
      "metadata": {
        "id": "Ay4o6ClebhmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the embedding model\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "texts = [doc.page_content for doc in data]\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embedder.encode(texts, convert_to_tensor=False)  # FAISS works with numpy arrays\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")"
      ],
      "metadata": {
        "id": "FCokgnXAb5Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[:4]"
      ],
      "metadata": {
        "id": "stDByip1cOsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "\n",
        "# Create a FAISS vector store from your documents and embeddings\n",
        "# Use SentenceTransformerEmbeddings to wrap your SentenceTransformer model\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "vector_store = FAISS.from_documents(\n",
        "    documents=data,\n",
        "    embedding=embeddings\n",
        ")\n",
        "\n",
        "# Save the index (optional, for reuse)\n",
        "vector_store.save_local(\"faiss_index\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "-Zl3Brm6c1fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(\"Hello, are you working?\"))"
      ],
      "metadata": {
        "id": "XtY2f8sTdz-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Set up the retriever\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})  # Retrieve top 3 matches\n",
        "\n",
        "# Create a RetrievalQA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",  # Combines retrieved docs into the prompt\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True  # Optional: see what was retrieved\n",
        ")\n",
        "\n",
        "# Test it\n",
        "query = \"what best products can men use and suggest me products to handle acne scars?\"\n",
        "result = qa_chain({\"query\": query})\n",
        "print(result[\"result\"])\n",
        "print(result[\"source_documents\"])"
      ],
      "metadata": {
        "id": "w4FZrFxzeCsr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}